{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('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', '2022-12-29 13:42:08')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os.path\n",
    "from functools import reduce\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ['CHAT_GPT_TOKEN']\n",
    "openai.api_key, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-29 14:35:44'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_summary(text: str, max_tokens, temperature=0.9, engine=\"davinci\") -> str:\n",
    "    max_total_tokens = 2049\n",
    "    text = f\"Please summarize the following text in {max_tokens} tokens: [{text}]\"\n",
    "    chunks = [text[i:i+max_total_tokens] for i in range(0, len(text), max_total_tokens)]\n",
    "    max_summary_tokens = int(max_tokens / len(chunks))\n",
    "    summaries = []\n",
    "    for chunck in chunks:\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt='Summarize: \"{text}\"',\n",
    "            max_tokens=max_summary_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0.6,\n",
    "            stop=[\"\\n\", \" Human:\", \" AI:\"]\n",
    "        )\n",
    "        summaries.append(response.choices[0].text)\n",
    "    summary = \" \".join(summaries)\n",
    "    return summary\n",
    "datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a test of the emergency broadcast system. This is only a test. If this had been an actual emergency, you would have been instructed to do something. This concludes this test of the emergency broadcast system.\"\n",
    "get_summary(text, 100, temperature=0.9, engine=\"text-davinci-003\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1095879b9a1d916a6b9b664f97b78d2a7c64a571dcf7276d826d3a287daf6da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
